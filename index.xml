<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic</title>
    <link>https://Stephanie-Weiss.github.io/</link>
      <atom:link href="https://Stephanie-Weiss.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Academic</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Stephanie-Weiss.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Academic</title>
      <link>https://Stephanie-Weiss.github.io/</link>
    </image>
    
    <item>
      <title>Python basics</title>
      <link>https://Stephanie-Weiss.github.io/courses/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/courses/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>https://Stephanie-Weiss.github.io/courses/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/courses/example/visualization/</guid>
      <description>&lt;p&gt;Learn how to visualize data with Plotly.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == &#39;Canada&#39;&amp;quot;)
fig = px.bar(data_canada, x=&#39;year&#39;, y=&#39;pop&#39;)
fig.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>https://Stephanie-Weiss.github.io/courses/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/courses/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://Stephanie-Weiss.github.io/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Welcome to Wowchemy, the website builder for Hugo</title>
      <link>https://Stephanie-Weiss.github.io/post/getting-started/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/post/getting-started/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;














&lt;figure  id=&#34;figure-the-template-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png&#34; alt=&#34;The template is mobile first with a responsive design to ensure that your site looks stunning on every device.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The template is mobile first with a responsive design to ensure that your site looks stunning on every device.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;get-started&#34;&gt;Get Started&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;üëâ &lt;a href=&#34;https://wowchemy.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìö &lt;a href=&#34;https://wowchemy.com/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí¨ &lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;Wowchemy community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üê¶ Twitter: &lt;a href=&#34;https://twitter.com/wowchemy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@wowchemy&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; &lt;a href=&#34;https://twitter.com/search?q=%28%23MadeWithWowchemy%20OR%20%23MadeWithAcademic%29&amp;amp;src=typed_query&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#MadeWithWowchemy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí° &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Wowchemy&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating Wowchemy?&lt;/strong&gt; View the &lt;a href=&#34;https://wowchemy.com/docs/guide/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/updates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-wowchemys-future-httpswowchemycomplans&#34;&gt;&lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy&amp;rsquo;s future ‚ù§Ô∏è&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt; awesome rewards and extra features ü¶Ñ‚ú®&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/wowchemy/hugo-academic-cli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Academic CLI&lt;/a&gt;:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out the latest &lt;strong&gt;demo&lt;/strong&gt;&lt;/a&gt; of what you&amp;rsquo;ll get in less than 10 minutes, or &lt;a href=&#34;https://wowchemy.com/user-stories/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;view the &lt;strong&gt;showcase&lt;/strong&gt;&lt;/a&gt; of personal, project, and business sites.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with &lt;a href=&#34;https://wowchemy.com/docs/page-builder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;widgets&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://wowchemy.com/docs/import/jupyter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://wowchemy.com/docs/install-locally/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://wowchemy.com/docs/customization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code highlighting and &lt;a href=&#34;https://en.wikibooks.org/wiki/LaTeX/Mathematics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LaTeX math&lt;/a&gt; supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Wowchemy and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the &lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt; to see it in action! Day/night mode can also be disabled by the site admin in &lt;code&gt;params.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/customization&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://Stephanie-Weiss.github.io/publication/conference-paper/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://Stephanie-Weiss.github.io/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://Stephanie-Weiss.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Imprint/Impressum</title>
      <link>https://Stephanie-Weiss.github.io/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://Stephanie-Weiss.github.io/terms/</guid>
      <description>&lt;h5 id=&#34;impressum&#34;&gt;Impressum&lt;/h5&gt;
&lt;br /&gt;
Angaben gem√§√ü ¬ß 5 TMG&lt;br /&gt;
Inhaltlich verantwortlich f√ºr den Inhalt der Website:&lt;br /&gt;
&lt;br /&gt;
Stephanie Weiss&lt;br /&gt;
Universit√§t Siegen&lt;br /&gt;
Kohlbettstr.15&lt;br /&gt;
57072 Siegen&lt;br /&gt;
&lt;br /&gt;
Kontakt&lt;br /&gt;
email: stephanie.weiss@uni-siegen.de
&lt;h5 id=&#34;imprint&#34;&gt;Imprint&lt;/h5&gt;
&lt;br /&gt;
Statement according to ¬ß 5 TMG&lt;br /&gt;
Responsible for the content of this website:&lt;br /&gt;
&lt;br /&gt;
Stephanie Weiss&lt;br /&gt;
Universit√§t Siegen&lt;br /&gt;
Kohlbettstr.15&lt;br /&gt;
57072 Siegen&lt;br /&gt;
&lt;br /&gt;
Contact&lt;br /&gt;
email: stephanie.weiss@uni-siegen.de
</description>
    </item>
    
    <item>
      <title>Privacy Policy/Datenschutz</title>
      <link>https://Stephanie-Weiss.github.io/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://Stephanie-Weiss.github.io/privacy/</guid>
      <description>&lt;h5 id=&#34;datenschutz&#34;&gt;Datenschutz&lt;/h5&gt;
&lt;p&gt;Ich speichere keine Informationen √ºber Besucher:innen dieser Webseite.
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Die Webseite wird bei GitHub Pages bereitgestellt. GitHub stellt umfassende Informationen zu den erhobenen und gespeicherten Daten im &lt;a href=&#34;https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Privacy Statement&lt;/strong&gt;&lt;/a&gt; bereit.&lt;/p&gt;
&lt;h5 id=&#34;privacy-information&#34;&gt;Privacy Information&lt;/h5&gt;
&lt;p&gt;I do not store any information about the visitors of this website.
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;This website is hosted by GitHub Pages. For more detailed information on the data collected and stored by GitHub please refer to the &lt;a href=&#34;https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Privacy Statement&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://Stephanie-Weiss.github.io/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>https://Stephanie-Weiss.github.io/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/project/internal-project/</guid>
      <description>&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Owing to advancing digitalization, consumers have become more fastidious about the story ventures create about themselves. The increased demand regarding the aesthetical representation of storytelling has prompted many entrepreneurs to trust upon more sophisticated forms, such as images and videos, to create an identity with which they aim to appeal to consumers. For research in the field of storytelling, this step of modernization entails innovating the methodological approaches adopted to analyze visual storytelling. Only then, scholars are able to make reliable statements about the influence of visual storytelling on, e.g., sales tracking. The sales giant Amazon has taken a step in this direction by offering its platform-owned ML-web services. In the scope of this article, it is looked at the potential two of these provided services, Amazon Transcribe (Automatic speech recognition) and Amazon Rekognition (Image and video analysis), hold for advancing the research field of storytelling.&lt;/p&gt;
&lt;p&gt;Figure 1: Photo by Kevin Ku on Unsplash&lt;/p&gt;
&lt;p&gt;Storytelling ‚Äì A Powerful, Well-Established Tool&lt;/p&gt;
&lt;p&gt;Push messages with image ads pop up on our smartphone screens, video ads interrupt the series we are watching, Facebook &amp;amp; Co. advertise goods we have searched for lately, surrounded by posts of our friends ‚Äì for those occurrences not to drown in the daily advertisement noise we are experiencing but to make us either focus, sympathize, or laugh, it is important for marketers to master the art of storytelling. Recently, I have watched a very inspiring TEDx Talk by David J. P. Phillips, a man who is known as ‚ÄúMr. Death by Power Point‚Äù, about how this can look like and what is the magic behind storytelling (&lt;a href=&#34;https://www.youtube.com/watch?v=Nj-hdQMa3uA&amp;amp;feature=youtu.be%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=Nj-hdQMa3uA&amp;feature=youtu.be)&lt;/a&gt;. Aside from him, there are numerous other supporters who attach a powerful role to storytelling (Figure 2).&lt;/p&gt;
&lt;p&gt;Figure 2: Photo by Florian Klauer on Unsplash&lt;/p&gt;
&lt;p&gt;Why storytelling should not be underrated and how ventures can benefit from an effective storytelling has been studied by several scholars (e.g., Lounsbury &amp;amp; Glynn, 2001; Martens, Jennings, &amp;amp; Devereaux Jennings, 2007; Navis &amp;amp; Glynn, 2010). In this article, however, I argue that according to the fact that stories are increasing in complexity regarding the interplay of audio track, images, music, etc. (Pohlgeers, 2019), it is time for a methodological revolution in the field of narratives, e.g., to get a better understanding of the impact they have on sales success. By doing so, I aim to push forward and contribute to visual storytelling as under-researched field. For this purpose, I want to introduce innovative methods and discuss their potential as well as their weaknesses for the analysis of storytelling, contributing to modern entrepreneurship research.&lt;/p&gt;
&lt;p&gt;Not only does storytelling work in an entrepreneurial context, but also scholars, to whom I count myself, have to tell a compelling story with their research papers in order to be published. I have been told once by a co-writer that there are three characteristics which make a paper ‚Äúsexy‚Äù and increase its publication chances: (1) new conceptional ideas, (2) an interesting data set, or (3) an innovative method. On the hunt for meeting one of these criteria with one of my research projects, I searched for new avenues in the field of storytelling. During this search, I stumbled upon Amazon Web Service (AWS), a massive platform that provides powerful tools, amongst others, based on artificial intelligence and machine learning, opening up new possibilities and solutions in all kinds of fields, including academic research. Especially the two tools Amazon Rekognition and Amazon Transcribe caught my interest by evoking enthusiasm for new methodological routes I could take in my research field of storytelling. Amazon Rekognition, forming part of facial recognition technologies (FRT), e.g., detects faces, objects, labels, text, safe content, and celebrities in images or videos, and Amazon Transcribe, which converts audio into text, could both revolutionize storytelling research in general and in an entrepreneurial context in particular. By understanding how elements involved in storytelling such as narratives, visuals, and images serve as mechanism to form a venture‚Äôs identity (Gehman &amp;amp; Soubli√®re, 2017), researchers could, on the one hand, make valuable contributions to legitimacy literature; on the other hand, they could advise ventures how to create a compelling identity through storytelling in order to be perceived as legitimate by consumers (Martens et al., 2007).&lt;/p&gt;
&lt;p&gt;Why Are New Methods Needed in The Field of Entrepreneurial Narratives?&lt;/p&gt;
&lt;p&gt;To better account for the power storytelling holds and finding adequate ways to methodologically, grasp the complexity of this today highly mediatized tool, I claim that new methods are needed in the field of storytelling or rather the maturing process of recently emerging methods should be advanced. An emerging methodological revolution already becomes apparent when exploring existing literature in Table 1. In particular during the last two decades, I observe a development from conceptual approaches to natural language processing (NLP). While several studies have examined narrational storytelling, the field of visual storytelling is just starting to become more prominent.&lt;/p&gt;
&lt;p&gt;Table 1: Literature review (1977-2020)
The reasons for new methods which advance research on visual storytelling to create untapped opportunities are twofold. First, innovative methods in this field provide new insights in the phenomenon of storytelling. Second, new combinations of different approaches arise with the aim of gaining a deeper understanding of storytelling and bring together a yet scattered research field (Lounsbury, Cornelissen, Granqvist, &amp;amp; Grodal, 2018). One such combination of approaches could be to investigate the relationship between aesthetics and innovation to gain new insights into sociocultural trends (Jancsary, Meyer, H√∂llerer, &amp;amp; Boxenbaum, 2018). By aesthetics, existing literature refers to a technological product‚Äôs design (Lounsbury et al., 2018). I argue, however, that this interpretation should be extended to a narrative‚Äôs design. Another avenue a study about modern entrepreneurship points at relates to research on storytelling as strategic means (√úberbacher, 2014) and how multiple linguistic constructs interplay (Lounsbury et al., 2018). To understand the dynamics stemming from this interplay, they motivate research on exploring interactions between contextual factors, such as spaces, places, objects, and language, all factors which scholars could examine with Amazon Rekognition and Amazon Transcribe.&lt;/p&gt;
&lt;p&gt;Moreover, I argue that what has already been established in video games user research (Mirza-Babaei, Long, Foley, &amp;amp; McAllister, 2011) could also be promising to overcome the lack of metrics and evaluation methods to measure story effectiveness of new ventures, such as interest stimulation, memorability, and informativeness (Kosara &amp;amp; MacKinlay, 2013) as well as capturing the interplay happening in storytelling. How methods such as video mining as current state of the art provides ways to advance business research in this field demonstrates a recent study in which scholars investigate the appeal of movie trailers (Schwenzow et al., 2020). Relying on biometric data generated through automated processes might, on the one hand, improve replicability of studies when compared to human rating (Chouinard, Scott, &amp;amp; Cusack, 2019), on the other hand, research using machine learning-based algorithms might not be prone to subjectivity issues but instead to error rates. Thus, I assume, at least for an early phase of artificial intelligence (AI), that it might be promising to be a two-timer, combining AI with human crosscheck through, e.g. the use of Amazon‚Äôs Mechanical Turk (MTurk) (Chan, Parhankangas, Sahaym, &amp;amp; Oo, 2019). This would allow for visualization studies which are not solely student-based (Kosara &amp;amp; MacKinlay, 2013), increasing their chances of being accepted at journals such as Entrepreneurship Theory and Practice, which abstains from papers with student-based data samples unless the research question shows a clear relevance for consulting students.&lt;/p&gt;
&lt;p&gt;Amazon Web Services (AWS) ‚Äì a Golden Fleece or a Pandora‚Äôs Box?&lt;/p&gt;
&lt;p&gt;A solely Amazon-based approach, on the other hand, might be a source of new, yet unforeseeable consequences. Hence, a question I am asking myself is whether AWS incarnates a Golden Fleece or a Pandora‚Äôs box with the big stirs Amazon as provider of the service platform is creating. These two concepts trace back to Greek mythology where The Golden Fleece is used as a symbol for something valuable with ‚Äúmagic power‚Äù and ‚Äúan object of worship‚Äù (Lordkipanidze, 2001, p. 3) that needs to be protected for ‚Äúwhoever owned the Fleece could reign!‚Äù (Lordkipanidze, 2001, p. 4). As opposed to this, a Pandora‚Äôs box is a proverb we use to refer to ‚Äúa source of unexpected troubles and pain‚Äù (Lordkipanidze, 2001, p. 33). From my point of view, AWS seems to perform a tightrope act with two forces pulling: tools leading to innovative solutions and improvements in diverse fields and a growing monopoly which is involved in a powerful surveillance system, and thus criticized for violating privacy rights, as well as for having momentous error rates and a biased algorithm (Blank, 2019). Before considering the tools provided by AWS for research purposes, I wanted to dig deeper and get an idea of how to estimate these three main concerns coming with the use of FRT in general and through an academic lens in particular.&lt;/p&gt;
&lt;p&gt;Facial Data ‚Äì Privacy Rights as Pitfall&lt;/p&gt;
&lt;p&gt;FRT have already entered several areas of our everyday lives. When we transition from one country to another, a snapshot is taken at the airport. Booking an accommodation via Airbnb requires storing our ID card. With our Face ID, we can unlock our iPhone. Facebook uses its ‚Äúphoto tag suggest‚Äù tool to identify our friends. Nowadays, this enumeration of FRT application fields seems to be endless. Although these technologies have positive contributions, facilitating our everyday lives, with the advance of FRT also come concerns whether our privacy rights remain unviolated.&lt;/p&gt;
&lt;p&gt;As an article by Whitener and Aragon (2019) shows privacy rights‚Äô violation is an explosive issue, reflecting in the General Data Protection Regulation (GDPR) (EU) and the Biometric Information Privacy Act (BIPA) (US). Both regulations distinguish between facial geometry and simple photographs. While the GDPR demands an active consent from the individual whose biometric data should be processed for identification purposes, the BIPA is limited to a mere disclosure duty (Whitener and Aragon, 2019).&lt;/p&gt;
&lt;p&gt;Figure 3: Photo by Nadine Shaabana on Unsplash
As a study has shown, people are willing to trade benefits for biometric privacy since they are not solely concerned by data security but also by its use (Kugler, 2019). Society strongly criticizes the use of FRT especially in the realm of law enforcement, such as border control and mass surveillance. ‚ÄúBorder management is becoming increasingly datalogical‚Äù (Mattern, 2018), leading to dehumanizing. ‚ÄúThe border-crosser becomes a pixelated subject[s] ‚Ä¶ composed of so many data points that the individual is no longer a meaningful category.‚Äù (Longo, 2017, p. 224). Also, political activists and protesters see this technology as danger (O‚ÄôNeill, 2019).&lt;/p&gt;
&lt;p&gt;The contested deployment of FRT and its potential for mistaken arrests (Fingas, 2018) induced over 100 Amazonians to issue a letter to Jeff Bezos, CEO of Amazon, asking to stop selling facial-recognition software to police and to start taking responsibility (Conger, 2018). The trigger for the request was the disclosure of the collaboration between Amazon, the government, and the police force by the non-profit organization The American Civil Liberties Union (ACLU), which is committed to protecting personal rights. The Amazonians saw a serious threat for marginalized groups through the use of Amazon Rekognition: ‚ÄúWe already know that in the midst of historic militarization of police, renewed targeting of Black activists, and the growth of a federal deportation force currently engaged in human rights abuses ‚Äî this will be another powerful tool for the surveillance state, and ultimately serve to harm the most marginalized‚Äù (Conger, 2018).&lt;/p&gt;
&lt;p&gt;Male Whites as Standard ‚Äì An Ongoing Legacy of Slavery and Colonial Times?&lt;/p&gt;
&lt;p&gt;Not only is FRT, such as Amazon Rekognition, seen critically due to&lt;/p&gt;
&lt;p&gt;Figure 4: Photo by Arshad Khan on Unsplash
violation of privacy rights, but also it raises concerns with regard to bias (Klare, Burge, Klontz, Bruegge, &amp;amp; Jain, 2012). This brings up the question of the type of bias and who is responsible for it. ‚ÄúAlgorithms themselves have no moral agency‚Äù (Blank, 2019, p. 6). As a consequence, they are only as good as the training data which their programmers feed them under the influence of their own cultural values. Does that imply that these algorithms do not provide improvements in terms of objectivity? Do they have to be deculturized first?&lt;/p&gt;
&lt;p&gt;Since most algorithms, such as, e.g., Microsoft, IBM, Google, and Amazon, have their origin in diversity lacking, American companies (Levin, 2019), Western culture is dominant in AI, which, as results of these algorithms show, marginalizes certain groups, i.e., women, as well as darker-skinned humans, reminding us of slavery and colonial times (Laura &amp;amp; Thomi, 2019; Magnet, 2011). As a study has shown, accuracy of APIs‚Äô results decreases by the following order of training data origin: Caucasian, Indian, Asian and African (Wang, Deng, Hu, Tao, &amp;amp; Huang, 2018). Low cultural distance between developers and the person to be identified improves outcomes of APIs (Beveridge, Givens, Phillips, Draper, &amp;amp; Lui, 2008), supporting the hypothesis that the culture of an algorithm‚Äôs origin is dominating. Compared to lighter-skinned males, for darker-skinned females error rates for gender misclassification are up to 34.4% (Buolamwini &amp;amp; Gebru, 2018). This high error rate even led to a classification of African American faces as gorillas by Google‚Äôs algorithm (Simonite, 2018).&lt;/p&gt;
&lt;p&gt;Figure 5: Photo by Prince Akachi on Unsplash&lt;/p&gt;
&lt;p&gt;Figure 6: Photo by Rob Tol on Unsplash&lt;/p&gt;
&lt;p&gt;As a study has shown, FRT are not only racist and sexist (Buolamwini &amp;amp; Gebru, 2018) but also age-discriminatory, indicated by an underrepresentation of underaged and elderly (Anda, Lillis, Le-Khac, &amp;amp; Scanlon, 2018). Hence, ‚Äúbiometric technologies not only fail to live up to promises of objectivity and reliability, but in fact continue a long history of misrecognizing women, people of color, and people with disabilities‚Äù (Mattern, 2018).&lt;/p&gt;
&lt;p&gt;Are Amazon Transcribe and Amazon Rekognition Useful and Reliable?&lt;/p&gt;
&lt;p&gt;Apart from concerns regarding privacy rights and bias, a key question that will determine the future of services such as Amazon Rekognition, especially when used for academic purposes, relates to their reliability. To test the usefulness and reliability of Amazon Transcribe and Amazon Rekognition and to exemplify how these tools could revolutionize current methodological approaches in storytelling, I, owing to an own interest in sustainable entrepreneurship, analyzed the following front video of a Kickstarter campaign (alternatively you can go to &lt;a href=&#34;https://www.youtube.com/watch?v=CxBoTMWQTd0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=CxBoTMWQTd0&lt;/a&gt; where only the Kickstarter dedication is missing). The video starts with a waterfall scenery representing the massive amount of water we use for our daily showers. Throughout the video four different subjects (1 man, 2 women, 1 girl) test the innovative, water-saving shower the company produces. The viewer learns about the journey of the company starting from the idea, going through a developmental design and engineering process, resulting in the final product of which water efficiency is demonstrated by the filling levels of two aquariums representing the water consumption during a ‚Äúnormal‚Äù shower compared to when using the innovative product. The story about the product‚Äôs journey is accompanied by meeting scenes in office rooms covered with sketches and close-ups of the product. Crowdfunding is an interesting environment to investigate visual storytelling since campaigns with a video are much more likely to reach their funding goals, whereas those without a video have a hard time receiving sufficient funding (Kickstarter, 2020).&lt;/p&gt;
&lt;p&gt;Amazon Transcribe ‚Äì from Speech to Text&lt;/p&gt;
&lt;p&gt;For a reliability check-up of Amazon Transcribe, first, I closely scrutinized the rendered transcript by comparing it to the original audio track in the sample video. Figure 7 displays the transcript with incorrectly transcribed parts which I emphasized in different colors and added corrections. With the help of these emphases, I evaluate total accuracy, group error types, and discuss consequences for academic analyses. In total, Amazon Transcribe shows an accuracy of 94,92% (incorrectly transcribes 33 out of 649 words (excluding sentence transition issues). Only 73 words have a confidence level below 85%. 26 of these 73 words (35,62%) are actually incorrectly transcribed. The different colors in Figure 7 represent different badness scales. While red-marked parts severely impact the transcript‚Äôs meaning (16), yellow-marked parts emphasize minor modifications (14), concerning mainly sentence-transition. I used brownish color to emphasize sample-specific errors, relating to the product‚Äôs name (10). I am pleasantly surprised how accurate Amazon Transcribe worked. When assigning the right weight to the confidence values, using Amazon Transcribe might facilitate investigating narratives embedded in videos in the future. Only analyses based on sentence length might be problematic due to the frequent errors occurring with sentence transition. Moreover, accuracy should be tested for different accents since Amazon Transcribe might have problems transcribing non-standard English.&lt;/p&gt;
&lt;p&gt;Figure 7: Output of Amazon Transcribe
After exploring Amazon Transcribe and its reliability, I turn to Amazon Rekognition. In the scope of this article, I focus on detecting faces and detecting labels as two provided commands. Due to copyright reasons, I took two random pictures (Figure 8 and Figure 9) that could fit the sample crowdfunding campaign I am using to demonstrate what can be done with the tools of interest provided by AWS. For detecting faces, a bounding box with landmarks is created. Based on this face measurement, age, gender, emotions, and other characteristics can be determined. Further information is given about the quality regarding brightness and sharpness as well as the face rotation.&lt;/p&gt;
&lt;p&gt;Table 2: Detect faces output for Figure 7&lt;/p&gt;
&lt;p&gt;Table 2: Detect faces output for Figure 7&lt;/p&gt;
&lt;p&gt;Figure 8: Photo by The Creative Exchange on Unsplash&lt;/p&gt;
&lt;p&gt;Table 3: Detect faces output for Figure 8&lt;/p&gt;
&lt;p&gt;Figure 9: Photo by Christian buehner on Unsplash&lt;/p&gt;
&lt;p&gt;For Figure 8 and Figure 9, results are for the most part reliable. Concerning age, I notice that with increasing age, the age range Amazon Rekognition gives seems to widen. This is in line with prior findings that Amazon Rekognition performs best ‚Äúfor all ranges up to the age of 29‚Äù (Anda et al., 2018, p.136).  The mean absolute age error estimation is 9.286. To exemplify this, for a woman at the age of 54, the system might render a result of 45. Error rates for males are lower (Anda et al., 2018). Amazon Rekognition‚Äôs perfomance for estimating humans at younger ages may already open up new ways to investigate the impact of infant behavior in visual storytelling (Chouinard et al., 2019). Also, results for gender correspond to the accuracy rates identified in recent studies (Jung, An, Kwak, Salminen, &amp;amp; Jansen, 2018; Yavuz, 2019). For emotions, Amazon Rekognition correctly considered happy and calm to be the dominant emotions in Figure 7 and 8 respectively. Being able to identify emotions in pictures will open up new possibilities to advance the field of collective indexing of emotions (Knautz and Stock, 2011; Reyes and Bahm, 2016). Only the confidence level for beard in Figure 8 is surprisingly low.&lt;/p&gt;
&lt;p&gt;Amazon Rekognition ‚Äì Detecting Labels&lt;/p&gt;
&lt;p&gt;For the sample video, Amazon Rekognition identifies 4640 labels. These labels refer to detected objects, scenes, and activities. Using the statistical software R, I requested the number of unique labels, which rendered a list of 288 unique labels, as displayed in Figure 10. 20,83% of the labels were incorrectly recognized. It stands out that 8,3% of the error labels result from misinterpreting the white bathroom gown which is worn by the woman who is showering in the video. Another 10% of the error labels represent situations in which many people come together. This assumption is based on the team meetings displayed in the video.&lt;/p&gt;
&lt;p&gt;Even though having a lower accuracy rate than Amazon Transcribe, Amazon Rekognition‚Äôs tool for detecting labels still convinced me of its usefulness for future research since most of the labels very well described the overall visual content of the video. Knowing the unique labels used in visual storytelling opens up new avenues to apply topic modeling and to explore interrelations between labels themselves as well as in comparison to spoken and/or written narratives. Since the labels come with start and end times, it is also possible to get a deeper understanding of how timing in terms of label detection impacts a video‚Äôs attractiveness.&lt;/p&gt;
&lt;p&gt;Figure 10: List of unique labels
Looking into the Crystal Ball ‚Äì What the Future May Hold for FRT in General and For Academia in Particular&lt;/p&gt;
&lt;p&gt;Accuracy rates are of central importance, especially in fields where based on FRT momentous decisions are made, such as prison sentence or even death penalty. This real threat imposed by FRT, such as Amazon Rekognition, has become omnipresent by the American Civil Liberties Union (ACLU) congress scandal at the latest, where 28 Congress members were falsely matched with persons involved in criminal actions grounded on a confidence level of 80% (Brandom, 2018). ACLU questioned the use of FRT in law enforcement (Snow, 2018). Matt Wood, general manager of AI at AWS, countered with arguing that the confidence level should be set to 90% for public safety issues (Wood, 2018b).&lt;/p&gt;
&lt;p&gt;What should be done with a tool that, on the one hand, is able to prevent ‚Äúhuman trafficking, inhibiting child exploitation, and reuniting missing children with their families‚Äù (Wood, 2018a); on the other hand, it violates privacy rights, discriminates marginalized groups, and has the power to send an innocent person to jail? AWS suggests that to benefit from this powerful tool society needs to prevent misuse of this technology (Wood, 2018b). To ensure this, an established ‚Äúethical infrastructure‚Äù is required (Floridi, 2013). Otherwise, mistrust might cast a shadow on FRT leverage, resulting in untapped opportunities for improvement, such as using FRT for recognizing objects and alert visually impaired if they become an obstacle for them (Tripathi, Halder, &amp;amp; Vanusha, 2018).&lt;/p&gt;
&lt;p&gt;To regulate FRTs‚Äô great power, government, technological companies, and society have to work hand in hand (Blank, 2019). With the help of such a ‚Äúdistributed agency‚Äù (Taddeo &amp;amp; Floridi, 2018), regulation is possible. According to Zeng et al. (2019), a responsible use of FRT includes six steps: (1) Improve data privacy, (2) improve accuracy and robustness, (3) reduce bias, (4) inform society, (5) create encrypted test data, (6) constantly check for ethical risks. These steps are congruent with the EU‚Äôs AI check list. First movements into this direction have been made in form of the GDPR and the BIPA. There are also first cases were bans and fine issues of FRT were issued (Dave Lee, 2019; Edvardsen, 2019; Fisher, 2019). How the distributed agency ensures the right use of FRT only time will tell. For FRT research not to become ‚Äúdangerous‚Äù and proverbially ‚Äúdeadly‚Äù, what Durrenmatt already warned of, also we as researchers have the responsibility to deal with data wisely and should be aware that the use of tools such as Amazon Transcribe and Amazon Rekognition not only processes data but also generates new ones.&lt;/p&gt;
&lt;p&gt;For using FRT for academic purposes, I can stress that automating processes through algorithms will facilitate data analysis, especially for larger data sets. On an individual level, errors caused by algorithms can have tremendous consequences, research based on large data sets, however, can prevent a serious distortion of results with the help of confidence values, robustness checks, and random human cross-check, at least in an early stage of machine learning. I believe that when having ensured reliability, services such as Amazon Transcribe and Amazon Rekognition have the power to revolutionize and modernize storytelling research by enabling new approaches which are capable of examining the complex interplay happening in storytelling.&lt;/p&gt;
&lt;p&gt;Overall, I think that retelling the methodological story in the field of visual storytelling is of relevance to three groups. Researchers can profit from using innovative methods in order to get a deeper understanding of the power of visual storytelling and learn about how to combine different methodological approaches. Moreover, new insights gained from the use of these innovative methods may help organizations in the future to enhance their performance by improving visual narratives. As a positive side-effect, society may profit from an improved shopping experience.&lt;/p&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;p&gt;Allison, T. H., Davis, B. C., Short, J. C., &amp;amp; Webb, J. W. (2014). Crowdfunding in a prosocial microlending environment: Examining the role of intrinsic versus extrinsic cues. Entrepreneurship: Theory and Practice, 39(1), 53‚Äì73. &lt;a href=&#34;https://doi.org/10.1111/etap.12108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/etap.12108&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Allison, T. H., McKenny, A. F., &amp;amp; Short, J. C. (2013). The effect of entrepreneurial rhetoric on microlending investment: An examination of the warm-glow effect. Journal of Business Venturing, 28(6), 690‚Äì707. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2013.01.003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2013.01.003&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anda, F., Lillis, D., Le-Khac, N. A., &amp;amp; Scanlon, M. (2018). Evaluating automated facial age estimation techniques for digital forensics. Proceedings ‚Äì 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018, 129‚Äì139. &lt;a href=&#34;https://doi.org/10.1109/SPW.2018.00028&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1109/SPW.2018.00028&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Beveridge, J. R., Givens, G. H., Phillips, P. J., Draper, B. A., &amp;amp; Lui, Y. M. (2008). Focus on quality, predicting frvt 2006 performance. IEEE International Conference, 1‚Äì8.&lt;/p&gt;
&lt;p&gt;Blank, A. L. (2019). Computer Vision Machine Learning and Future- Oriented Ethics.&lt;/p&gt;
&lt;p&gt;Brandom, R. (2018). Amazon‚Äôs facial recognition matched 28 members of Congress to criminal mugshots. Retrieved from &lt;a href=&#34;https://www.theverge.com/2018/7/26/17615634/amazon-rekognition-aclu-mug-shot-congress-facial-recognition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.theverge.com/2018/7/26/17615634/amazon-rekognition-aclu-mug-shot-congress-facial-recognition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Buolamwini, J., &amp;amp; Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research, 81, 1‚Äì15.&lt;/p&gt;
&lt;p&gt;Chan, C. S. R., Parhankangas, A., Sahaym, A., &amp;amp; Oo, P. (2019). Bellwether and the herd? Unpacking the u-shaped relationship between prior funding and subsequent contributions in reward-based crowdfunding. Journal of Business Venturing, (April), 1‚Äì24. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2019.04.002&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2019.04.002&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chouinard, B., Scott, K., &amp;amp; Cusack, R. (2019). Using automatic face analysis to score infant behaviour from video collected online. Infant Behavior and Development, 54(May 2018), 1‚Äì12. &lt;a href=&#34;https://doi.org/10.1016/j.infbeh.2018.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.infbeh.2018.11.004&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Clarke, J. (2011). Revitalizing Entrepreneurship: How Visual Symbols are Used in Entrepreneurial Performances. Journal of Management Studies, 48(6), 1365‚Äì1391. &lt;a href=&#34;https://doi.org/10.1111/j.1467-6486.2010.01002.x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/j.1467-6486.2010.01002.x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Conger, K. (2018). Amazon Workers Demand Jeff Bezos Cancel Face Recognition Contracts With Law Enforcement. Retrieved from &lt;a href=&#34;https://gizmodo.com/1827071904#&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gizmodo.com/1827071904#&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Dave Lee, L. (2019). San Francisco Bans Facial Recognition in US First. Retrieved from &lt;a href=&#34;https://www.bbc.com/news/technology-48276660&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.bbc.com/news/technology-48276660&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Davis, B. C., Hmieleski, K. M., Webb, J. W., &amp;amp; Coombs, J. E. (2017). Funders‚Äô positive affective reactions to entrepreneurs‚Äô crowdfunding pitches: The influence of perceived product creativity and entrepreneurial passion. Journal of Business Venturing, 32(1), 90‚Äì106. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2016.10.006&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2016.10.006&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Edvardsen, S. (2019). How to Interpret Sweden‚Äôs First GDPR Fine on Facial Recognition in School. Retrieved from iapp.org/news/a/how-to-interpret-swedens-first-gdpr-fine-on- facial-recognition-in-school/&lt;/p&gt;
&lt;p&gt;Escalas, J. E. (2004). Imagine Yourself in the Product‚ÄØ: Mental Simulation , Narrative Transportation , and Persuasion. Journal of Advertising, 33(2), 37‚Äì48.&lt;/p&gt;
&lt;p&gt;Fingas, J. (2018). Police Face Recognition Misidentified 2,300 as Potential CriminalsEngadget. Retrieved from &lt;a href=&#34;https://www.engadget.com/2018/05/06/police-face-recognition-&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.engadget.com/2018/05/06/police-face-recognition-&lt;/a&gt; misidentified-2300-as-criminals/&lt;/p&gt;
&lt;p&gt;Fisher, C. (2019). Oakland Bans City Use of Facial Recognition Software. Retrieved from &lt;a href=&#34;https://www.engadget.com/2019/07/17/oakland-california-facial-recognition-ban/?guccounter=1&amp;amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;amp;guce_referrer_sig=AQAAAJS9qvqVURBnqMcqWMh86nAuwExGTWYKwfXo7L39UmZL-8pThjwuDzgGLv4XnmSn8-3_Mpaugef0ahbJGurHEGqMvKfOj92oRHiRJTg9D9zjYpWmKsfHVL5Mqnq2f3gJ_VIgjmlF9S-xSh0xfeFD_Pp8V9hBluysCMHdPKXZJ8pn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.engadget.com/2019/07/17/oakland-california-facial-recognition-ban/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAJS9qvqVURBnqMcqWMh86nAuwExGTWYKwfXo7L39UmZL-8pThjwuDzgGLv4XnmSn8-3_Mpaugef0ahbJGurHEGqMvKfOj92oRHiRJTg9D9zjYpWmKsfHVL5Mqnq2f3gJ_VIgjmlF9S-xSh0xfeFD_Pp8V9hBluysCMHdPKXZJ8pn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Floridi, L. (2013). Distrubted Moraility in an Information Society. Science and Engineering Ethics, 19(3), 727‚Äì743.&lt;/p&gt;
&lt;p&gt;Garud, R., Schildt, H. A., &amp;amp; Lant, T. K. (2014). Entrepreneurial Storytelling, Future Expectations, and the Paradox of Legitimacy. Organization Science, 25(5), 1479‚Äì1492. &lt;a href=&#34;https://doi.org/10.1287/orsc.2014.0915&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1287/orsc.2014.0915&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gehman, J., &amp;amp; Soubli√®re, J. F. (2017). Cultural entrepreneurship: from making culture to cultural making. Innovation: Management, Policy and Practice, 19(1), 61‚Äì73. &lt;a href=&#34;https://doi.org/10.1080/14479338.2016.1268521&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1080/14479338.2016.1268521&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Golant, B. D., &amp;amp; Sillince, J. A. A. (2007). The Constitution of Organizational Legitimacy: A Narrative Perspective. Organization Studies, 28(8), 1149‚Äì1167. &lt;a href=&#34;https://doi.org/10.1177/0170840607075671&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1177/0170840607075671&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hanjalic, A., &amp;amp; Xu, L. Q. (2005). Affective video content representation and modeling. IEEE Transactions on Multimedia, 7(1), 143‚Äì154. &lt;a href=&#34;https://doi.org/10.1109/TMM.2004.840618&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1109/TMM.2004.840618&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jancsary, D., Meyer, R., H√∂llerer, M. A., &amp;amp; Boxenbaum, E. (2018). Institutions as multimodal accomplishments: Towards the analysis of visual registers. Research in the Sociology of Organizations, 54A, 87‚Äì117.&lt;/p&gt;
&lt;p&gt;Jung, S. G., An, J., Kwak, H., Salminen, J., &amp;amp; Jansen, B. J. (2018). Assessing the accuracy of four popular face recognition tools for inferring gender, age, and race. 12th International AAAI Conference on Web and Social Media, ICWSM 2018, (Icwsm), 624‚Äì627.&lt;/p&gt;
&lt;p&gt;Kaminski, J., Jiang, Y., Piller, F., &amp;amp; Hopp, C. (2017). Do user entrepreneurs speak different? Applying natural language processing to crowdfunding videos. Conference on Human Factors in Computing Systems ‚Äì Proceedings, 2683‚Äì2689. &lt;a href=&#34;https://doi.org/10.1145/3027063.3053223&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1145/3027063.3053223&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kickstarter. (2020). How to make an awesome video. Retrieved from &lt;a href=&#34;https://www.kickstarter.com/blog/how-to-make-an-awesome-video&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.kickstarter.com/blog/how-to-make-an-awesome-video&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Klare, B., Burge, M., Klontz, J., Bruegge, R., &amp;amp; Jain, A. (2012). Face Recognition Performance: Role of Demographic Information. IEEE Transactions on Information Forensics and Security, 7(6). &lt;a href=&#34;https://doi.org/10.1109/TIFS.2012.2214212&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1109/TIFS.2012.2214212&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Knautz, K., &amp;amp; Stock, W. G. (2011). Collective indexing of emotions in videos. Journal of Documentation, 67(6), 975‚Äì994. &lt;a href=&#34;https://doi.org/10.1108/00220411111183555&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1108/00220411111183555&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kosara, R., &amp;amp; MacKinlay, J. (2013). Storytelling: The next step for visualization. Computer, 46(5), 44‚Äì50. &lt;a href=&#34;https://doi.org/10.1109/MC.2013.36&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1109/MC.2013.36&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kugler, M. B. (2019). From Identification to Identity Theft: Public Perceptions of Biometric Privacy Harms. SSRN Electronic Journal. &lt;a href=&#34;https://doi.org/10.2139/ssrn.3289850&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.2139/ssrn.3289850&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Laura, A., &amp;amp; Thomi, B. (2019). European Master ‚Äô s Degree in Human Rights and Democratisation The Impact of Biometric Systems at EU Outside Borders on the Human Rights of Irregular Migrating Women.&lt;/p&gt;
&lt;p&gt;Levin, S. (2019). ‚ÄúBias deep inside the code‚Äù: the problem with AI ‚Äúethics‚Äù in Silicon Valley. Retrieved from &lt;a href=&#34;https://www.theguardian.com/technology/2019/mar/28/big-tech-ai-ethics-&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.theguardian.com/technology/2019/mar/28/big-tech-ai-ethics-&lt;/a&gt; boards-prejudice&lt;/p&gt;
&lt;p&gt;Longo, M. (2017). The Politics of Borders: Sovereignty, Security, and the Citizen after 9/11. Cambridge University Press.&lt;/p&gt;
&lt;p&gt;Lordkipanidze, O. (2001). The Golden Fleece: Myth, Euhemeristic Explanation and Archaeology. Oxford Journal of Archaeology, 20(1), 1‚Äì38. &lt;a href=&#34;https://doi.org/10.1111/1468-0092.00121&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/1468-0092.00121&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lounsbury, M., Cornelissen, J., Granqvist, N., &amp;amp; Grodal, S. (2018). Culture, innovation and entrepreneurship. Innovation: Management, Policy and Practice, 21(1), 1‚Äì12. &lt;a href=&#34;https://doi.org/10.1080/14479338.2018.1537716&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1080/14479338.2018.1537716&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lounsbury, M., &amp;amp; Glynn, M. A. (2001). Cultural entrepreneurship: Stories, legitimacy, and the acquisition of resources. Strategic Management Journal, 22(6‚Äì7), 545‚Äì564. &lt;a href=&#34;https://doi.org/10.1002/smj.188&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1002/smj.188&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Magnet, S. A. (2011). When Biometrics Fail: Gender, Race, and the Technology of Identity. Duke University Press.&lt;/p&gt;
&lt;p&gt;Manning, S., &amp;amp; Bejarano, T. A. (2017). Convincing the crowd: Entrepreneurial storytelling in crowdfunding campaigns. Strategic Organization, 15(2), 194‚Äì219. &lt;a href=&#34;https://doi.org/10.1177/1476127016648500&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1177/1476127016648500&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Martens, M. L., Jennings, J. E., &amp;amp; Devereaux Jennings, P. (2007). Do the Stories They Tell Get Them the Money They Need? The Role of Entrepreneurial Narratives in Resource Acquisition. Academy of Management Journal, 50(5), 1107‚Äì1132.&lt;/p&gt;
&lt;p&gt;Mattern, S. (2018). All Eyes on the Border. Places Journal. &lt;a href=&#34;https://doi.org/10.22269/180925&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.22269/180925&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mirza-Babaei, P., Long, S., Foley, E., &amp;amp; McAllister, G. (2011). Understanding the contribution of biometrics to games user research. Proceedings of DiGRA 2011 Conference: Think Design Play, (October).&lt;/p&gt;
&lt;p&gt;Mitra, T., &amp;amp; Gilbert, E. (2014). The language that gets people to give. CSCW, 49‚Äì61. &lt;a href=&#34;https://doi.org/10.1145/2531602.2531656&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1145/2531602.2531656&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moss, T. W., Renko, M., Block, E., &amp;amp; Meyskens, M. (2017). Funding the story of hybrid ventures: Crowdfunder lending preferences and linguistic hybridity. Journal of Business Venturing, 33(5), 643‚Äì659. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2017.12.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2017.12.004&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Navis, C., &amp;amp; Glynn, M. A. (2010). How New Market Categories Emerge‚ÄØ: Radio Satellite. Administrative Science Quarterly, 55, 439‚Äì471.&lt;/p&gt;
&lt;p&gt;Navis, C., &amp;amp; Glynn, M. A. (2011). Legitimate distinctiveness and the entrepreneurial identity: Influence on investor judgments of new venture plausibility. Academy of Management Review, 36(3), 479‚Äì499.&lt;/p&gt;
&lt;p&gt;O‚ÄôNeill, K. (2019). ‚ÄúFacebook‚Äôs ‚Äò10 Year Challenge‚Äô Is Just a Harmless Meme- Right?‚Äù&lt;/p&gt;
&lt;p&gt;Parhankangas, A., &amp;amp; Renko, M. (2017). Linguistic style and crowdfunding success among social and commercial entrepreneurs. Journal of Business Venturing, 32(2), 215‚Äì236. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2016.11.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2016.11.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pollack, J. M., Rutherford, M. W., &amp;amp; Nagy, B. G. (2012). Preparedness and cognitive legitimacy as antecedents of new venture funding in televised business pitches. Entrepreneurship: Theory and Practice, 36(5), 915‚Äì939. &lt;a href=&#34;https://doi.org/10.1111/j.1540-6520.2012.00531.x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/j.1540-6520.2012.00531.x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Resnik, A., &amp;amp; Stern, B. L. (1977). An Analysis of Information Content in Television Advertising. Journal of Marketing, 41(1), 50‚Äì53.&lt;/p&gt;
&lt;p&gt;Reyes, J., &amp;amp; Bahm, C. R. (2016). Crowdfunding: Applying collective indexing of emotions to campaign videos. Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW, 26-Februar, 385‚Äì388. &lt;a href=&#34;https://doi.org/10.1145/2818052.2869075&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1145/2818052.2869075&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Roundy, P. (2009). Doing good by telling stories: emotion in social entrepreneurship communication. Journal of Small Business Strategy, 19(2), 41‚Äì69.&lt;/p&gt;
&lt;p&gt;Sahouria, E., &amp;amp; Avideh, Z. (1999). Content Analysis of Video Using Principal Components. Journal of the American Statistical Association, 9(8), 1290‚Äì1298. &lt;a href=&#34;https://doi.org/10.1080/01621459.1936.10503354&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1080/01621459.1936.10503354&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schwenzow, J., Hartmann, J., Schikowsky, A., &amp;amp; Heitmann, M. (2020). Understanding Videos at Scale‚ÄØ: How to Extract Insights for Business Research.&lt;/p&gt;
&lt;p&gt;Simonite, T. (2018). When It Comes to Gorillas, Google Photos Remains Blind. Retrieved from &lt;a href=&#34;https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Snow, J. (2018). Amazon‚Äôs Face Recognition Falsely Matched 28 Members of Congress With Mugshots. ACLU. Retrieved from &lt;a href=&#34;https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Taddeo, M., &amp;amp; Floridi, L. (2018). How AI Can Be a Force for Good. Science, 361(6404), 751‚Äì752.&lt;/p&gt;
&lt;p&gt;Tripathi, S., Halder, C., &amp;amp; Vanusha, D. (2018). A Survey on Assistive Technology for the Visually Impaired. International Research Journal of Engineering and Technology (IRJET), 1152‚Äì1155.&lt;/p&gt;
&lt;p&gt;√úberbacher, F. (2014). Legitimation of New Ventures: A Review and Research Programme. Journal of Management Studies, 51(4), 667‚Äì698. &lt;a href=&#34;https://doi.org/10.1111/joms.12077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/joms.12077&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;van Werven, R., Bouwmeester, O., &amp;amp; Cornelissen, J. P. (2015). The power of arguments: How entrepreneurs convince stakeholders of the legitimate distinctiveness of their ventures. Journal of Business Venturing, 30(4), 616‚Äì631. &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2014.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2014.08.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wang, M., Deng, W., Hu, J., Tao, X., &amp;amp; Huang, Y. (2018). Racial Faces in-the-Wild: Reducing Racial Bias by Information Maximization Adaptation Network. Retrieved from &lt;a href=&#34;http://arxiv.org/abs/1812.00194&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://arxiv.org/abs/1812.00194&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wehnert, P., Baccarella, C. V., &amp;amp; Beckmann, M. (2019). In crowdfunding we trust? Investigating crowdfunding success as a signal for enhancing trust in sustainable product features. Technological Forecasting and Social Change, 141, 128‚Äì137. &lt;a href=&#34;https://doi.org/10.1016/j.techfore.2018.06.036&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.techfore.2018.06.036&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Whitener, M., &amp;amp; Aragon, R. (2019). How should we regulate facial-recognition technology?&lt;/p&gt;
&lt;p&gt;Wood, M. (2018a). Amazon general manager of artificial intelligence highlights positive uses of Rekognition &amp;amp; acceptable use policy. Business &amp;amp; Human Rights Resource Center. Retrieved from &lt;a href=&#34;https://www.business-humanrights.org/en/amazon-general-manager-of-artificial-intelligence-highlights-positive-uses-of-rekognition-acceptable-use-policy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.business-humanrights.org/en/amazon-general-manager-of-artificial-intelligence-highlights-positive-uses-of-rekognition-acceptable-use-policy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wood, M. (2018b). Thoughts On Machine Learning Accuracy. Retrieved from &lt;a href=&#34;https://aws.amazon.com/blogs/aws/thoughts-on-machine-learning-accuracy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://aws.amazon.com/blogs/aws/thoughts-on-machine-learning-accuracy/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wry, T., Lounsbury, M., &amp;amp; Glynn, M. A. (2011). Legitimating Nascent Collective Identities: Coordinating Cultural Entrepreneurship. Organization Science, 22(2), 449‚Äì463. &lt;a href=&#34;https://doi.org/10.1287/orsc.1100.0613&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1287/orsc.1100.0613&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Xu, P., Chen, L., &amp;amp; Santhanam, R. (2015). Will video be the next generation of e-commerce product reviews? Presentation format and the role of product type. Decision Support Systems, 73, 85‚Äì96. &lt;a href=&#34;https://doi.org/10.1016/j.dss.2015.03.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.dss.2015.03.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yang, S., Kher, R., &amp;amp; Newbert, S. L. (2019). What signals matter for social startups? It depends: The influence of gender role congruity on social impact accelerator selection decisions. Journal of Business Venturing, (March). &lt;a href=&#34;https://doi.org/10.1016/j.jbusvent.2019.03.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jbusvent.2019.03.001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yavuz, A. (2019). Evaluierung cloudbasierter Machine Learning Services, 49. Retrieved from &lt;a href=&#34;http://edoc.sub.uni-hamburg.de/haw/volltexte/2019/4531/pdf/Thesis.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://edoc.sub.uni-hamburg.de/haw/volltexte/2019/4531/pdf/Thesis.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zeng, Y., Lu, E., Sun, Y., &amp;amp; Tian, R. (2019). Responsible Facial Recognition and Beyond. Retrieved from &lt;a href=&#34;https://arxiv.org/pdf/1909.12935.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/1909.12935.pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://Stephanie-Weiss.github.io/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://Stephanie-Weiss.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://Stephanie-Weiss.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
